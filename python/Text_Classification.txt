import pandas as pd 
import numpy as np
import sys
reload(sys)
sys.setdefaultencoding('utf-8')
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction import DictVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer

####### Amazon product review data, feature including "ASIN", "Brand", "Title", "ImageURL", "Category" ######

### loading data ##########
Training_data=pd.read_excel('path') ## file path  ex. read_table 
Test_data=pd.read_excel('path') #### file path  ex. read_table 
Cate_data=pd.read_excel('path') ### ## file path  ex. read_table 
cate_list=list(Cate_data.values.astype(str).flatten())
#print Training_data.head(10)
#print Training_data.info()
#cate_name=Training_data.CategoryName.unique()
############################
#1. Text feature classification 
#2. URL feature classification 
#3. image feature classification 
############################

###### #1 Text(title) feature classification  #####
## Create X_train data ( => vector)
x_train=Training_data[['Title']].astype(str)
x_train=x_train['Title'].tolist()
#print x_train[0:10]
count_vect = CountVectorizer()
vectorizer = TfidfTransformer()
x_train_counts = count_vect.fit_transform(x_train)
#vectorizer = TfidfVectorizer(min_df=1)
x_train_tf=vectorizer.fit_transform(x_train_counts)
#### Create y_train data  #######
y_train=Training_data['CategoryName']
########## test model ###########
x_test=Test_data[['Title']].astype(str)
x_test=x_test['Title'].tolist()
x_test_counts = count_vect.transform(x_test)
x_test_tf=vectorizer.transform(x_test_counts)
print x_test_tf.shape
################### Multi Nomial Bayes ###############################
'''
clf = MultinomialNB().fit(x_train_tf, y_train)
predicted = clf.predict(x_test_tf)
for product, category in zip(x_test,predicted):
	print('%r => %s => %s' % (product, category in cate_list, category))

'''
####################  Decision Tree Classifier  ####################### 
'''
from sklearn import tree
clf_2 = tree.DecisionTreeClassifier().fit(x_train_tf,y_train)
predicted_2 = clf_2.predict(x_test_tf)
for product, category in zip(x_test,predicted_2):
	print('%r => %s => %s' % (product, category in cate_list, category))
'''
####################  Neural Newwork (Supervised) #####################
'''
from sklearn.neural_network import MLPClassifier
clf_3 = MLPClassifier(solver='adam', alpha=0.1, random_state=10).fit(x_train_tf,y_train)
#clf_4= MLPClassifier(solver='sgd', alpha=1e-5, random_state=10)
predicted_3 = clf_3.predict(x_test_tf)
for product, category in zip(x_test,predicted_3):
	print('%r => %s => %s' % (product, category in cate_list, category))
'''
#################### Stochastic Gradient Descent ################################
'''
from sklearn.linear_model import SGDClassifier
clf_5 = SGDClassifier(loss='hinge',alpha=0.01).fit(x_train_tf,y_train)
predicted_5 = clf_5.predict(x_test_tf)
for product, category in zip(x_test,predicted_5):
	print('%r => %s => %s' % (product, category in cate_list, category))
'''
##################################################################################